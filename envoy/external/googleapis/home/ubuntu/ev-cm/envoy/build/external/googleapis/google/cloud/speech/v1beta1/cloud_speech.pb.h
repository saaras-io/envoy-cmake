// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1beta1/cloud_speech.proto

#ifndef PROTOBUF_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto__INCLUDED
#define PROTOBUF_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3005000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3005000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "google/api/annotations.pb.h"
#include "google/longrunning/operations.pb.h"
#include <google/protobuf/duration.pb.h>
#include <google/protobuf/timestamp.pb.h>
#include "google/rpc/status.pb.h"
// @@protoc_insertion_point(includes)

namespace protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[14];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
void InitDefaultsSyncRecognizeRequestImpl();
void InitDefaultsSyncRecognizeRequest();
void InitDefaultsAsyncRecognizeRequestImpl();
void InitDefaultsAsyncRecognizeRequest();
void InitDefaultsStreamingRecognizeRequestImpl();
void InitDefaultsStreamingRecognizeRequest();
void InitDefaultsStreamingRecognitionConfigImpl();
void InitDefaultsStreamingRecognitionConfig();
void InitDefaultsRecognitionConfigImpl();
void InitDefaultsRecognitionConfig();
void InitDefaultsSpeechContextImpl();
void InitDefaultsSpeechContext();
void InitDefaultsRecognitionAudioImpl();
void InitDefaultsRecognitionAudio();
void InitDefaultsSyncRecognizeResponseImpl();
void InitDefaultsSyncRecognizeResponse();
void InitDefaultsAsyncRecognizeResponseImpl();
void InitDefaultsAsyncRecognizeResponse();
void InitDefaultsAsyncRecognizeMetadataImpl();
void InitDefaultsAsyncRecognizeMetadata();
void InitDefaultsStreamingRecognizeResponseImpl();
void InitDefaultsStreamingRecognizeResponse();
void InitDefaultsStreamingRecognitionResultImpl();
void InitDefaultsStreamingRecognitionResult();
void InitDefaultsSpeechRecognitionResultImpl();
void InitDefaultsSpeechRecognitionResult();
void InitDefaultsSpeechRecognitionAlternativeImpl();
void InitDefaultsSpeechRecognitionAlternative();
inline void InitDefaults() {
  InitDefaultsSyncRecognizeRequest();
  InitDefaultsAsyncRecognizeRequest();
  InitDefaultsStreamingRecognizeRequest();
  InitDefaultsStreamingRecognitionConfig();
  InitDefaultsRecognitionConfig();
  InitDefaultsSpeechContext();
  InitDefaultsRecognitionAudio();
  InitDefaultsSyncRecognizeResponse();
  InitDefaultsAsyncRecognizeResponse();
  InitDefaultsAsyncRecognizeMetadata();
  InitDefaultsStreamingRecognizeResponse();
  InitDefaultsStreamingRecognitionResult();
  InitDefaultsSpeechRecognitionResult();
  InitDefaultsSpeechRecognitionAlternative();
}
}  // namespace protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto
namespace google {
namespace cloud {
namespace speech {
namespace v1beta1 {
class AsyncRecognizeMetadata;
class AsyncRecognizeMetadataDefaultTypeInternal;
extern AsyncRecognizeMetadataDefaultTypeInternal _AsyncRecognizeMetadata_default_instance_;
class AsyncRecognizeRequest;
class AsyncRecognizeRequestDefaultTypeInternal;
extern AsyncRecognizeRequestDefaultTypeInternal _AsyncRecognizeRequest_default_instance_;
class AsyncRecognizeResponse;
class AsyncRecognizeResponseDefaultTypeInternal;
extern AsyncRecognizeResponseDefaultTypeInternal _AsyncRecognizeResponse_default_instance_;
class RecognitionAudio;
class RecognitionAudioDefaultTypeInternal;
extern RecognitionAudioDefaultTypeInternal _RecognitionAudio_default_instance_;
class RecognitionConfig;
class RecognitionConfigDefaultTypeInternal;
extern RecognitionConfigDefaultTypeInternal _RecognitionConfig_default_instance_;
class SpeechContext;
class SpeechContextDefaultTypeInternal;
extern SpeechContextDefaultTypeInternal _SpeechContext_default_instance_;
class SpeechRecognitionAlternative;
class SpeechRecognitionAlternativeDefaultTypeInternal;
extern SpeechRecognitionAlternativeDefaultTypeInternal _SpeechRecognitionAlternative_default_instance_;
class SpeechRecognitionResult;
class SpeechRecognitionResultDefaultTypeInternal;
extern SpeechRecognitionResultDefaultTypeInternal _SpeechRecognitionResult_default_instance_;
class StreamingRecognitionConfig;
class StreamingRecognitionConfigDefaultTypeInternal;
extern StreamingRecognitionConfigDefaultTypeInternal _StreamingRecognitionConfig_default_instance_;
class StreamingRecognitionResult;
class StreamingRecognitionResultDefaultTypeInternal;
extern StreamingRecognitionResultDefaultTypeInternal _StreamingRecognitionResult_default_instance_;
class StreamingRecognizeRequest;
class StreamingRecognizeRequestDefaultTypeInternal;
extern StreamingRecognizeRequestDefaultTypeInternal _StreamingRecognizeRequest_default_instance_;
class StreamingRecognizeResponse;
class StreamingRecognizeResponseDefaultTypeInternal;
extern StreamingRecognizeResponseDefaultTypeInternal _StreamingRecognizeResponse_default_instance_;
class SyncRecognizeRequest;
class SyncRecognizeRequestDefaultTypeInternal;
extern SyncRecognizeRequestDefaultTypeInternal _SyncRecognizeRequest_default_instance_;
class SyncRecognizeResponse;
class SyncRecognizeResponseDefaultTypeInternal;
extern SyncRecognizeResponseDefaultTypeInternal _SyncRecognizeResponse_default_instance_;
}  // namespace v1beta1
}  // namespace speech
}  // namespace cloud
}  // namespace google
namespace google {
namespace cloud {
namespace speech {
namespace v1beta1 {

enum RecognitionConfig_AudioEncoding {
  RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED = 0,
  RecognitionConfig_AudioEncoding_LINEAR16 = 1,
  RecognitionConfig_AudioEncoding_FLAC = 2,
  RecognitionConfig_AudioEncoding_MULAW = 3,
  RecognitionConfig_AudioEncoding_AMR = 4,
  RecognitionConfig_AudioEncoding_AMR_WB = 5,
  RecognitionConfig_AudioEncoding_RecognitionConfig_AudioEncoding_INT_MIN_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32min,
  RecognitionConfig_AudioEncoding_RecognitionConfig_AudioEncoding_INT_MAX_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32max
};
bool RecognitionConfig_AudioEncoding_IsValid(int value);
const RecognitionConfig_AudioEncoding RecognitionConfig_AudioEncoding_AudioEncoding_MIN = RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED;
const RecognitionConfig_AudioEncoding RecognitionConfig_AudioEncoding_AudioEncoding_MAX = RecognitionConfig_AudioEncoding_AMR_WB;
const int RecognitionConfig_AudioEncoding_AudioEncoding_ARRAYSIZE = RecognitionConfig_AudioEncoding_AudioEncoding_MAX + 1;

const ::google::protobuf::EnumDescriptor* RecognitionConfig_AudioEncoding_descriptor();
inline const ::std::string& RecognitionConfig_AudioEncoding_Name(RecognitionConfig_AudioEncoding value) {
  return ::google::protobuf::internal::NameOfEnum(
    RecognitionConfig_AudioEncoding_descriptor(), value);
}
inline bool RecognitionConfig_AudioEncoding_Parse(
    const ::std::string& name, RecognitionConfig_AudioEncoding* value) {
  return ::google::protobuf::internal::ParseNamedEnum<RecognitionConfig_AudioEncoding>(
    RecognitionConfig_AudioEncoding_descriptor(), name, value);
}
enum StreamingRecognizeResponse_EndpointerType {
  StreamingRecognizeResponse_EndpointerType_ENDPOINTER_EVENT_UNSPECIFIED = 0,
  StreamingRecognizeResponse_EndpointerType_START_OF_SPEECH = 1,
  StreamingRecognizeResponse_EndpointerType_END_OF_SPEECH = 2,
  StreamingRecognizeResponse_EndpointerType_END_OF_AUDIO = 3,
  StreamingRecognizeResponse_EndpointerType_END_OF_UTTERANCE = 4,
  StreamingRecognizeResponse_EndpointerType_StreamingRecognizeResponse_EndpointerType_INT_MIN_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32min,
  StreamingRecognizeResponse_EndpointerType_StreamingRecognizeResponse_EndpointerType_INT_MAX_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32max
};
bool StreamingRecognizeResponse_EndpointerType_IsValid(int value);
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse_EndpointerType_EndpointerType_MIN = StreamingRecognizeResponse_EndpointerType_ENDPOINTER_EVENT_UNSPECIFIED;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse_EndpointerType_EndpointerType_MAX = StreamingRecognizeResponse_EndpointerType_END_OF_UTTERANCE;
const int StreamingRecognizeResponse_EndpointerType_EndpointerType_ARRAYSIZE = StreamingRecognizeResponse_EndpointerType_EndpointerType_MAX + 1;

const ::google::protobuf::EnumDescriptor* StreamingRecognizeResponse_EndpointerType_descriptor();
inline const ::std::string& StreamingRecognizeResponse_EndpointerType_Name(StreamingRecognizeResponse_EndpointerType value) {
  return ::google::protobuf::internal::NameOfEnum(
    StreamingRecognizeResponse_EndpointerType_descriptor(), value);
}
inline bool StreamingRecognizeResponse_EndpointerType_Parse(
    const ::std::string& name, StreamingRecognizeResponse_EndpointerType* value) {
  return ::google::protobuf::internal::ParseNamedEnum<StreamingRecognizeResponse_EndpointerType>(
    StreamingRecognizeResponse_EndpointerType_descriptor(), name, value);
}
// ===================================================================

class SyncRecognizeRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SyncRecognizeRequest) */ {
 public:
  SyncRecognizeRequest();
  virtual ~SyncRecognizeRequest();

  SyncRecognizeRequest(const SyncRecognizeRequest& from);

  inline SyncRecognizeRequest& operator=(const SyncRecognizeRequest& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SyncRecognizeRequest(SyncRecognizeRequest&& from) noexcept
    : SyncRecognizeRequest() {
    *this = ::std::move(from);
  }

  inline SyncRecognizeRequest& operator=(SyncRecognizeRequest&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const SyncRecognizeRequest& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SyncRecognizeRequest* internal_default_instance() {
    return reinterpret_cast<const SyncRecognizeRequest*>(
               &_SyncRecognizeRequest_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    0;

  void Swap(SyncRecognizeRequest* other);
  friend void swap(SyncRecognizeRequest& a, SyncRecognizeRequest& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SyncRecognizeRequest* New() const PROTOBUF_FINAL { return New(NULL); }

  SyncRecognizeRequest* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const SyncRecognizeRequest& from);
  void MergeFrom(const SyncRecognizeRequest& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(SyncRecognizeRequest* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  bool has_config() const;
  void clear_config();
  static const int kConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::RecognitionConfig& config() const;
  ::google::cloud::speech::v1beta1::RecognitionConfig* release_config();
  ::google::cloud::speech::v1beta1::RecognitionConfig* mutable_config();
  void set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config);

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  bool has_audio() const;
  void clear_audio();
  static const int kAudioFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::RecognitionAudio& audio() const;
  ::google::cloud::speech::v1beta1::RecognitionAudio* release_audio();
  ::google::cloud::speech::v1beta1::RecognitionAudio* mutable_audio();
  void set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SyncRecognizeRequest)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::cloud::speech::v1beta1::RecognitionConfig* config_;
  ::google::cloud::speech::v1beta1::RecognitionAudio* audio_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsSyncRecognizeRequestImpl();
};
// -------------------------------------------------------------------

class AsyncRecognizeRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.AsyncRecognizeRequest) */ {
 public:
  AsyncRecognizeRequest();
  virtual ~AsyncRecognizeRequest();

  AsyncRecognizeRequest(const AsyncRecognizeRequest& from);

  inline AsyncRecognizeRequest& operator=(const AsyncRecognizeRequest& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  AsyncRecognizeRequest(AsyncRecognizeRequest&& from) noexcept
    : AsyncRecognizeRequest() {
    *this = ::std::move(from);
  }

  inline AsyncRecognizeRequest& operator=(AsyncRecognizeRequest&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const AsyncRecognizeRequest& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const AsyncRecognizeRequest* internal_default_instance() {
    return reinterpret_cast<const AsyncRecognizeRequest*>(
               &_AsyncRecognizeRequest_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    1;

  void Swap(AsyncRecognizeRequest* other);
  friend void swap(AsyncRecognizeRequest& a, AsyncRecognizeRequest& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline AsyncRecognizeRequest* New() const PROTOBUF_FINAL { return New(NULL); }

  AsyncRecognizeRequest* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const AsyncRecognizeRequest& from);
  void MergeFrom(const AsyncRecognizeRequest& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(AsyncRecognizeRequest* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  bool has_config() const;
  void clear_config();
  static const int kConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::RecognitionConfig& config() const;
  ::google::cloud::speech::v1beta1::RecognitionConfig* release_config();
  ::google::cloud::speech::v1beta1::RecognitionConfig* mutable_config();
  void set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config);

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  bool has_audio() const;
  void clear_audio();
  static const int kAudioFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::RecognitionAudio& audio() const;
  ::google::cloud::speech::v1beta1::RecognitionAudio* release_audio();
  ::google::cloud::speech::v1beta1::RecognitionAudio* mutable_audio();
  void set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::cloud::speech::v1beta1::RecognitionConfig* config_;
  ::google::cloud::speech::v1beta1::RecognitionAudio* audio_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsAsyncRecognizeRequestImpl();
};
// -------------------------------------------------------------------

class StreamingRecognizeRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognizeRequest) */ {
 public:
  StreamingRecognizeRequest();
  virtual ~StreamingRecognizeRequest();

  StreamingRecognizeRequest(const StreamingRecognizeRequest& from);

  inline StreamingRecognizeRequest& operator=(const StreamingRecognizeRequest& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StreamingRecognizeRequest(StreamingRecognizeRequest&& from) noexcept
    : StreamingRecognizeRequest() {
    *this = ::std::move(from);
  }

  inline StreamingRecognizeRequest& operator=(StreamingRecognizeRequest&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognizeRequest& default_instance();

  enum StreamingRequestCase {
    kStreamingConfig = 1,
    kAudioContent = 2,
    STREAMING_REQUEST_NOT_SET = 0,
  };

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StreamingRecognizeRequest* internal_default_instance() {
    return reinterpret_cast<const StreamingRecognizeRequest*>(
               &_StreamingRecognizeRequest_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    2;

  void Swap(StreamingRecognizeRequest* other);
  friend void swap(StreamingRecognizeRequest& a, StreamingRecognizeRequest& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StreamingRecognizeRequest* New() const PROTOBUF_FINAL { return New(NULL); }

  StreamingRecognizeRequest* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const StreamingRecognizeRequest& from);
  void MergeFrom(const StreamingRecognizeRequest& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(StreamingRecognizeRequest* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
  bool has_streaming_config() const;
  void clear_streaming_config();
  static const int kStreamingConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::StreamingRecognitionConfig& streaming_config() const;
  ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* release_streaming_config();
  ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* mutable_streaming_config();
  void set_allocated_streaming_config(::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config);

  // bytes audio_content = 2;
  private:
  bool has_audio_content() const;
  public:
  void clear_audio_content();
  static const int kAudioContentFieldNumber = 2;
  const ::std::string& audio_content() const;
  void set_audio_content(const ::std::string& value);
  #if LANG_CXX11
  void set_audio_content(::std::string&& value);
  #endif
  void set_audio_content(const char* value);
  void set_audio_content(const void* value, size_t size);
  ::std::string* mutable_audio_content();
  ::std::string* release_audio_content();
  void set_allocated_audio_content(::std::string* audio_content);

  StreamingRequestCase streaming_request_case() const;
  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
 private:
  void set_has_streaming_config();
  void set_has_audio_content();

  inline bool has_streaming_request() const;
  void clear_streaming_request();
  inline void clear_has_streaming_request();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  union StreamingRequestUnion {
    StreamingRequestUnion() {}
    ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config_;
    ::google::protobuf::internal::ArenaStringPtr audio_content_;
  } streaming_request_;
  mutable int _cached_size_;
  ::google::protobuf::uint32 _oneof_case_[1];

  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsStreamingRecognizeRequestImpl();
};
// -------------------------------------------------------------------

class StreamingRecognitionConfig : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognitionConfig) */ {
 public:
  StreamingRecognitionConfig();
  virtual ~StreamingRecognitionConfig();

  StreamingRecognitionConfig(const StreamingRecognitionConfig& from);

  inline StreamingRecognitionConfig& operator=(const StreamingRecognitionConfig& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StreamingRecognitionConfig(StreamingRecognitionConfig&& from) noexcept
    : StreamingRecognitionConfig() {
    *this = ::std::move(from);
  }

  inline StreamingRecognitionConfig& operator=(StreamingRecognitionConfig&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognitionConfig& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StreamingRecognitionConfig* internal_default_instance() {
    return reinterpret_cast<const StreamingRecognitionConfig*>(
               &_StreamingRecognitionConfig_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    3;

  void Swap(StreamingRecognitionConfig* other);
  friend void swap(StreamingRecognitionConfig& a, StreamingRecognitionConfig& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StreamingRecognitionConfig* New() const PROTOBUF_FINAL { return New(NULL); }

  StreamingRecognitionConfig* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const StreamingRecognitionConfig& from);
  void MergeFrom(const StreamingRecognitionConfig& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(StreamingRecognitionConfig* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  bool has_config() const;
  void clear_config();
  static const int kConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::RecognitionConfig& config() const;
  ::google::cloud::speech::v1beta1::RecognitionConfig* release_config();
  ::google::cloud::speech::v1beta1::RecognitionConfig* mutable_config();
  void set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config);

  // bool single_utterance = 2;
  void clear_single_utterance();
  static const int kSingleUtteranceFieldNumber = 2;
  bool single_utterance() const;
  void set_single_utterance(bool value);

  // bool interim_results = 3;
  void clear_interim_results();
  static const int kInterimResultsFieldNumber = 3;
  bool interim_results() const;
  void set_interim_results(bool value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::cloud::speech::v1beta1::RecognitionConfig* config_;
  bool single_utterance_;
  bool interim_results_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsStreamingRecognitionConfigImpl();
};
// -------------------------------------------------------------------

class RecognitionConfig : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.RecognitionConfig) */ {
 public:
  RecognitionConfig();
  virtual ~RecognitionConfig();

  RecognitionConfig(const RecognitionConfig& from);

  inline RecognitionConfig& operator=(const RecognitionConfig& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RecognitionConfig(RecognitionConfig&& from) noexcept
    : RecognitionConfig() {
    *this = ::std::move(from);
  }

  inline RecognitionConfig& operator=(RecognitionConfig&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const RecognitionConfig& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RecognitionConfig* internal_default_instance() {
    return reinterpret_cast<const RecognitionConfig*>(
               &_RecognitionConfig_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    4;

  void Swap(RecognitionConfig* other);
  friend void swap(RecognitionConfig& a, RecognitionConfig& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RecognitionConfig* New() const PROTOBUF_FINAL { return New(NULL); }

  RecognitionConfig* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const RecognitionConfig& from);
  void MergeFrom(const RecognitionConfig& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(RecognitionConfig* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  typedef RecognitionConfig_AudioEncoding AudioEncoding;
  static const AudioEncoding ENCODING_UNSPECIFIED =
    RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED;
  static const AudioEncoding LINEAR16 =
    RecognitionConfig_AudioEncoding_LINEAR16;
  static const AudioEncoding FLAC =
    RecognitionConfig_AudioEncoding_FLAC;
  static const AudioEncoding MULAW =
    RecognitionConfig_AudioEncoding_MULAW;
  static const AudioEncoding AMR =
    RecognitionConfig_AudioEncoding_AMR;
  static const AudioEncoding AMR_WB =
    RecognitionConfig_AudioEncoding_AMR_WB;
  static inline bool AudioEncoding_IsValid(int value) {
    return RecognitionConfig_AudioEncoding_IsValid(value);
  }
  static const AudioEncoding AudioEncoding_MIN =
    RecognitionConfig_AudioEncoding_AudioEncoding_MIN;
  static const AudioEncoding AudioEncoding_MAX =
    RecognitionConfig_AudioEncoding_AudioEncoding_MAX;
  static const int AudioEncoding_ARRAYSIZE =
    RecognitionConfig_AudioEncoding_AudioEncoding_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  AudioEncoding_descriptor() {
    return RecognitionConfig_AudioEncoding_descriptor();
  }
  static inline const ::std::string& AudioEncoding_Name(AudioEncoding value) {
    return RecognitionConfig_AudioEncoding_Name(value);
  }
  static inline bool AudioEncoding_Parse(const ::std::string& name,
      AudioEncoding* value) {
    return RecognitionConfig_AudioEncoding_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // string language_code = 3;
  void clear_language_code();
  static const int kLanguageCodeFieldNumber = 3;
  const ::std::string& language_code() const;
  void set_language_code(const ::std::string& value);
  #if LANG_CXX11
  void set_language_code(::std::string&& value);
  #endif
  void set_language_code(const char* value);
  void set_language_code(const char* value, size_t size);
  ::std::string* mutable_language_code();
  ::std::string* release_language_code();
  void set_allocated_language_code(::std::string* language_code);

  // .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
  bool has_speech_context() const;
  void clear_speech_context();
  static const int kSpeechContextFieldNumber = 6;
  const ::google::cloud::speech::v1beta1::SpeechContext& speech_context() const;
  ::google::cloud::speech::v1beta1::SpeechContext* release_speech_context();
  ::google::cloud::speech::v1beta1::SpeechContext* mutable_speech_context();
  void set_allocated_speech_context(::google::cloud::speech::v1beta1::SpeechContext* speech_context);

  // .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
  void clear_encoding();
  static const int kEncodingFieldNumber = 1;
  ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding encoding() const;
  void set_encoding(::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding value);

  // int32 sample_rate = 2;
  void clear_sample_rate();
  static const int kSampleRateFieldNumber = 2;
  ::google::protobuf::int32 sample_rate() const;
  void set_sample_rate(::google::protobuf::int32 value);

  // int32 max_alternatives = 4;
  void clear_max_alternatives();
  static const int kMaxAlternativesFieldNumber = 4;
  ::google::protobuf::int32 max_alternatives() const;
  void set_max_alternatives(::google::protobuf::int32 value);

  // bool profanity_filter = 5;
  void clear_profanity_filter();
  static const int kProfanityFilterFieldNumber = 5;
  bool profanity_filter() const;
  void set_profanity_filter(bool value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionConfig)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr language_code_;
  ::google::cloud::speech::v1beta1::SpeechContext* speech_context_;
  int encoding_;
  ::google::protobuf::int32 sample_rate_;
  ::google::protobuf::int32 max_alternatives_;
  bool profanity_filter_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsRecognitionConfigImpl();
};
// -------------------------------------------------------------------

class SpeechContext : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SpeechContext) */ {
 public:
  SpeechContext();
  virtual ~SpeechContext();

  SpeechContext(const SpeechContext& from);

  inline SpeechContext& operator=(const SpeechContext& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SpeechContext(SpeechContext&& from) noexcept
    : SpeechContext() {
    *this = ::std::move(from);
  }

  inline SpeechContext& operator=(SpeechContext&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const SpeechContext& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SpeechContext* internal_default_instance() {
    return reinterpret_cast<const SpeechContext*>(
               &_SpeechContext_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    5;

  void Swap(SpeechContext* other);
  friend void swap(SpeechContext& a, SpeechContext& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SpeechContext* New() const PROTOBUF_FINAL { return New(NULL); }

  SpeechContext* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const SpeechContext& from);
  void MergeFrom(const SpeechContext& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(SpeechContext* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string phrases = 1;
  int phrases_size() const;
  void clear_phrases();
  static const int kPhrasesFieldNumber = 1;
  const ::std::string& phrases(int index) const;
  ::std::string* mutable_phrases(int index);
  void set_phrases(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_phrases(int index, ::std::string&& value);
  #endif
  void set_phrases(int index, const char* value);
  void set_phrases(int index, const char* value, size_t size);
  ::std::string* add_phrases();
  void add_phrases(const ::std::string& value);
  #if LANG_CXX11
  void add_phrases(::std::string&& value);
  #endif
  void add_phrases(const char* value);
  void add_phrases(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& phrases() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_phrases();

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechContext)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::std::string> phrases_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsSpeechContextImpl();
};
// -------------------------------------------------------------------

class RecognitionAudio : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.RecognitionAudio) */ {
 public:
  RecognitionAudio();
  virtual ~RecognitionAudio();

  RecognitionAudio(const RecognitionAudio& from);

  inline RecognitionAudio& operator=(const RecognitionAudio& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RecognitionAudio(RecognitionAudio&& from) noexcept
    : RecognitionAudio() {
    *this = ::std::move(from);
  }

  inline RecognitionAudio& operator=(RecognitionAudio&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const RecognitionAudio& default_instance();

  enum AudioSourceCase {
    kContent = 1,
    kUri = 2,
    AUDIO_SOURCE_NOT_SET = 0,
  };

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RecognitionAudio* internal_default_instance() {
    return reinterpret_cast<const RecognitionAudio*>(
               &_RecognitionAudio_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    6;

  void Swap(RecognitionAudio* other);
  friend void swap(RecognitionAudio& a, RecognitionAudio& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RecognitionAudio* New() const PROTOBUF_FINAL { return New(NULL); }

  RecognitionAudio* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const RecognitionAudio& from);
  void MergeFrom(const RecognitionAudio& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(RecognitionAudio* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // bytes content = 1;
  private:
  bool has_content() const;
  public:
  void clear_content();
  static const int kContentFieldNumber = 1;
  const ::std::string& content() const;
  void set_content(const ::std::string& value);
  #if LANG_CXX11
  void set_content(::std::string&& value);
  #endif
  void set_content(const char* value);
  void set_content(const void* value, size_t size);
  ::std::string* mutable_content();
  ::std::string* release_content();
  void set_allocated_content(::std::string* content);

  // string uri = 2;
  private:
  bool has_uri() const;
  public:
  void clear_uri();
  static const int kUriFieldNumber = 2;
  const ::std::string& uri() const;
  void set_uri(const ::std::string& value);
  #if LANG_CXX11
  void set_uri(::std::string&& value);
  #endif
  void set_uri(const char* value);
  void set_uri(const char* value, size_t size);
  ::std::string* mutable_uri();
  ::std::string* release_uri();
  void set_allocated_uri(::std::string* uri);

  AudioSourceCase audio_source_case() const;
  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionAudio)
 private:
  void set_has_content();
  void set_has_uri();

  inline bool has_audio_source() const;
  void clear_audio_source();
  inline void clear_has_audio_source();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  union AudioSourceUnion {
    AudioSourceUnion() {}
    ::google::protobuf::internal::ArenaStringPtr content_;
    ::google::protobuf::internal::ArenaStringPtr uri_;
  } audio_source_;
  mutable int _cached_size_;
  ::google::protobuf::uint32 _oneof_case_[1];

  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsRecognitionAudioImpl();
};
// -------------------------------------------------------------------

class SyncRecognizeResponse : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SyncRecognizeResponse) */ {
 public:
  SyncRecognizeResponse();
  virtual ~SyncRecognizeResponse();

  SyncRecognizeResponse(const SyncRecognizeResponse& from);

  inline SyncRecognizeResponse& operator=(const SyncRecognizeResponse& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SyncRecognizeResponse(SyncRecognizeResponse&& from) noexcept
    : SyncRecognizeResponse() {
    *this = ::std::move(from);
  }

  inline SyncRecognizeResponse& operator=(SyncRecognizeResponse&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const SyncRecognizeResponse& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SyncRecognizeResponse* internal_default_instance() {
    return reinterpret_cast<const SyncRecognizeResponse*>(
               &_SyncRecognizeResponse_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    7;

  void Swap(SyncRecognizeResponse* other);
  friend void swap(SyncRecognizeResponse& a, SyncRecognizeResponse& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SyncRecognizeResponse* New() const PROTOBUF_FINAL { return New(NULL); }

  SyncRecognizeResponse* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const SyncRecognizeResponse& from);
  void MergeFrom(const SyncRecognizeResponse& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(SyncRecognizeResponse* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  int results_size() const;
  void clear_results();
  static const int kResultsFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& results(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* mutable_results(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* add_results();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
      mutable_results();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
      results() const;

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SyncRecognizeResponse)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult > results_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsSyncRecognizeResponseImpl();
};
// -------------------------------------------------------------------

class AsyncRecognizeResponse : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.AsyncRecognizeResponse) */ {
 public:
  AsyncRecognizeResponse();
  virtual ~AsyncRecognizeResponse();

  AsyncRecognizeResponse(const AsyncRecognizeResponse& from);

  inline AsyncRecognizeResponse& operator=(const AsyncRecognizeResponse& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  AsyncRecognizeResponse(AsyncRecognizeResponse&& from) noexcept
    : AsyncRecognizeResponse() {
    *this = ::std::move(from);
  }

  inline AsyncRecognizeResponse& operator=(AsyncRecognizeResponse&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const AsyncRecognizeResponse& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const AsyncRecognizeResponse* internal_default_instance() {
    return reinterpret_cast<const AsyncRecognizeResponse*>(
               &_AsyncRecognizeResponse_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    8;

  void Swap(AsyncRecognizeResponse* other);
  friend void swap(AsyncRecognizeResponse& a, AsyncRecognizeResponse& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline AsyncRecognizeResponse* New() const PROTOBUF_FINAL { return New(NULL); }

  AsyncRecognizeResponse* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const AsyncRecognizeResponse& from);
  void MergeFrom(const AsyncRecognizeResponse& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(AsyncRecognizeResponse* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  int results_size() const;
  void clear_results();
  static const int kResultsFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& results(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* mutable_results(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* add_results();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
      mutable_results();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
      results() const;

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult > results_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsAsyncRecognizeResponseImpl();
};
// -------------------------------------------------------------------

class AsyncRecognizeMetadata : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.AsyncRecognizeMetadata) */ {
 public:
  AsyncRecognizeMetadata();
  virtual ~AsyncRecognizeMetadata();

  AsyncRecognizeMetadata(const AsyncRecognizeMetadata& from);

  inline AsyncRecognizeMetadata& operator=(const AsyncRecognizeMetadata& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  AsyncRecognizeMetadata(AsyncRecognizeMetadata&& from) noexcept
    : AsyncRecognizeMetadata() {
    *this = ::std::move(from);
  }

  inline AsyncRecognizeMetadata& operator=(AsyncRecognizeMetadata&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const AsyncRecognizeMetadata& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const AsyncRecognizeMetadata* internal_default_instance() {
    return reinterpret_cast<const AsyncRecognizeMetadata*>(
               &_AsyncRecognizeMetadata_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    9;

  void Swap(AsyncRecognizeMetadata* other);
  friend void swap(AsyncRecognizeMetadata& a, AsyncRecognizeMetadata& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline AsyncRecognizeMetadata* New() const PROTOBUF_FINAL { return New(NULL); }

  AsyncRecognizeMetadata* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const AsyncRecognizeMetadata& from);
  void MergeFrom(const AsyncRecognizeMetadata& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(AsyncRecognizeMetadata* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // .google.protobuf.Timestamp start_time = 2;
  bool has_start_time() const;
  void clear_start_time();
  static const int kStartTimeFieldNumber = 2;
  const ::google::protobuf::Timestamp& start_time() const;
  ::google::protobuf::Timestamp* release_start_time();
  ::google::protobuf::Timestamp* mutable_start_time();
  void set_allocated_start_time(::google::protobuf::Timestamp* start_time);

  // .google.protobuf.Timestamp last_update_time = 3;
  bool has_last_update_time() const;
  void clear_last_update_time();
  static const int kLastUpdateTimeFieldNumber = 3;
  const ::google::protobuf::Timestamp& last_update_time() const;
  ::google::protobuf::Timestamp* release_last_update_time();
  ::google::protobuf::Timestamp* mutable_last_update_time();
  void set_allocated_last_update_time(::google::protobuf::Timestamp* last_update_time);

  // int32 progress_percent = 1;
  void clear_progress_percent();
  static const int kProgressPercentFieldNumber = 1;
  ::google::protobuf::int32 progress_percent() const;
  void set_progress_percent(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::Timestamp* start_time_;
  ::google::protobuf::Timestamp* last_update_time_;
  ::google::protobuf::int32 progress_percent_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsAsyncRecognizeMetadataImpl();
};
// -------------------------------------------------------------------

class StreamingRecognizeResponse : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognizeResponse) */ {
 public:
  StreamingRecognizeResponse();
  virtual ~StreamingRecognizeResponse();

  StreamingRecognizeResponse(const StreamingRecognizeResponse& from);

  inline StreamingRecognizeResponse& operator=(const StreamingRecognizeResponse& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StreamingRecognizeResponse(StreamingRecognizeResponse&& from) noexcept
    : StreamingRecognizeResponse() {
    *this = ::std::move(from);
  }

  inline StreamingRecognizeResponse& operator=(StreamingRecognizeResponse&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognizeResponse& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StreamingRecognizeResponse* internal_default_instance() {
    return reinterpret_cast<const StreamingRecognizeResponse*>(
               &_StreamingRecognizeResponse_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    10;

  void Swap(StreamingRecognizeResponse* other);
  friend void swap(StreamingRecognizeResponse& a, StreamingRecognizeResponse& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StreamingRecognizeResponse* New() const PROTOBUF_FINAL { return New(NULL); }

  StreamingRecognizeResponse* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const StreamingRecognizeResponse& from);
  void MergeFrom(const StreamingRecognizeResponse& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(StreamingRecognizeResponse* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  typedef StreamingRecognizeResponse_EndpointerType EndpointerType;
  static const EndpointerType ENDPOINTER_EVENT_UNSPECIFIED =
    StreamingRecognizeResponse_EndpointerType_ENDPOINTER_EVENT_UNSPECIFIED;
  static const EndpointerType START_OF_SPEECH =
    StreamingRecognizeResponse_EndpointerType_START_OF_SPEECH;
  static const EndpointerType END_OF_SPEECH =
    StreamingRecognizeResponse_EndpointerType_END_OF_SPEECH;
  static const EndpointerType END_OF_AUDIO =
    StreamingRecognizeResponse_EndpointerType_END_OF_AUDIO;
  static const EndpointerType END_OF_UTTERANCE =
    StreamingRecognizeResponse_EndpointerType_END_OF_UTTERANCE;
  static inline bool EndpointerType_IsValid(int value) {
    return StreamingRecognizeResponse_EndpointerType_IsValid(value);
  }
  static const EndpointerType EndpointerType_MIN =
    StreamingRecognizeResponse_EndpointerType_EndpointerType_MIN;
  static const EndpointerType EndpointerType_MAX =
    StreamingRecognizeResponse_EndpointerType_EndpointerType_MAX;
  static const int EndpointerType_ARRAYSIZE =
    StreamingRecognizeResponse_EndpointerType_EndpointerType_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  EndpointerType_descriptor() {
    return StreamingRecognizeResponse_EndpointerType_descriptor();
  }
  static inline const ::std::string& EndpointerType_Name(EndpointerType value) {
    return StreamingRecognizeResponse_EndpointerType_Name(value);
  }
  static inline bool EndpointerType_Parse(const ::std::string& name,
      EndpointerType* value) {
    return StreamingRecognizeResponse_EndpointerType_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
  int results_size() const;
  void clear_results();
  static const int kResultsFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::StreamingRecognitionResult& results(int index) const;
  ::google::cloud::speech::v1beta1::StreamingRecognitionResult* mutable_results(int index);
  ::google::cloud::speech::v1beta1::StreamingRecognitionResult* add_results();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >*
      mutable_results();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >&
      results() const;

  // .google.rpc.Status error = 1;
  bool has_error() const;
  void clear_error();
  static const int kErrorFieldNumber = 1;
  const ::google::rpc::Status& error() const;
  ::google::rpc::Status* release_error();
  ::google::rpc::Status* mutable_error();
  void set_allocated_error(::google::rpc::Status* error);

  // int32 result_index = 3;
  void clear_result_index();
  static const int kResultIndexFieldNumber = 3;
  ::google::protobuf::int32 result_index() const;
  void set_result_index(::google::protobuf::int32 value);

  // .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
  void clear_endpointer_type();
  static const int kEndpointerTypeFieldNumber = 4;
  ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType endpointer_type() const;
  void set_endpointer_type(::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult > results_;
  ::google::rpc::Status* error_;
  ::google::protobuf::int32 result_index_;
  int endpointer_type_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsStreamingRecognizeResponseImpl();
};
// -------------------------------------------------------------------

class StreamingRecognitionResult : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognitionResult) */ {
 public:
  StreamingRecognitionResult();
  virtual ~StreamingRecognitionResult();

  StreamingRecognitionResult(const StreamingRecognitionResult& from);

  inline StreamingRecognitionResult& operator=(const StreamingRecognitionResult& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StreamingRecognitionResult(StreamingRecognitionResult&& from) noexcept
    : StreamingRecognitionResult() {
    *this = ::std::move(from);
  }

  inline StreamingRecognitionResult& operator=(StreamingRecognitionResult&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognitionResult& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StreamingRecognitionResult* internal_default_instance() {
    return reinterpret_cast<const StreamingRecognitionResult*>(
               &_StreamingRecognitionResult_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    11;

  void Swap(StreamingRecognitionResult* other);
  friend void swap(StreamingRecognitionResult& a, StreamingRecognitionResult& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StreamingRecognitionResult* New() const PROTOBUF_FINAL { return New(NULL); }

  StreamingRecognitionResult* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const StreamingRecognitionResult& from);
  void MergeFrom(const StreamingRecognitionResult& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(StreamingRecognitionResult* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  int alternatives_size() const;
  void clear_alternatives();
  static const int kAlternativesFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& alternatives(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* mutable_alternatives(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* add_alternatives();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
      mutable_alternatives();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
      alternatives() const;

  // bool is_final = 2;
  void clear_is_final();
  static const int kIsFinalFieldNumber = 2;
  bool is_final() const;
  void set_is_final(bool value);

  // float stability = 3;
  void clear_stability();
  static const int kStabilityFieldNumber = 3;
  float stability() const;
  void set_stability(float value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognitionResult)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative > alternatives_;
  bool is_final_;
  float stability_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsStreamingRecognitionResultImpl();
};
// -------------------------------------------------------------------

class SpeechRecognitionResult : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SpeechRecognitionResult) */ {
 public:
  SpeechRecognitionResult();
  virtual ~SpeechRecognitionResult();

  SpeechRecognitionResult(const SpeechRecognitionResult& from);

  inline SpeechRecognitionResult& operator=(const SpeechRecognitionResult& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SpeechRecognitionResult(SpeechRecognitionResult&& from) noexcept
    : SpeechRecognitionResult() {
    *this = ::std::move(from);
  }

  inline SpeechRecognitionResult& operator=(SpeechRecognitionResult&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const SpeechRecognitionResult& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SpeechRecognitionResult* internal_default_instance() {
    return reinterpret_cast<const SpeechRecognitionResult*>(
               &_SpeechRecognitionResult_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    12;

  void Swap(SpeechRecognitionResult* other);
  friend void swap(SpeechRecognitionResult& a, SpeechRecognitionResult& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SpeechRecognitionResult* New() const PROTOBUF_FINAL { return New(NULL); }

  SpeechRecognitionResult* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const SpeechRecognitionResult& from);
  void MergeFrom(const SpeechRecognitionResult& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(SpeechRecognitionResult* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  int alternatives_size() const;
  void clear_alternatives();
  static const int kAlternativesFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& alternatives(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* mutable_alternatives(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* add_alternatives();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
      mutable_alternatives();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
      alternatives() const;

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechRecognitionResult)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative > alternatives_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsSpeechRecognitionResultImpl();
};
// -------------------------------------------------------------------

class SpeechRecognitionAlternative : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SpeechRecognitionAlternative) */ {
 public:
  SpeechRecognitionAlternative();
  virtual ~SpeechRecognitionAlternative();

  SpeechRecognitionAlternative(const SpeechRecognitionAlternative& from);

  inline SpeechRecognitionAlternative& operator=(const SpeechRecognitionAlternative& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SpeechRecognitionAlternative(SpeechRecognitionAlternative&& from) noexcept
    : SpeechRecognitionAlternative() {
    *this = ::std::move(from);
  }

  inline SpeechRecognitionAlternative& operator=(SpeechRecognitionAlternative&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const SpeechRecognitionAlternative& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SpeechRecognitionAlternative* internal_default_instance() {
    return reinterpret_cast<const SpeechRecognitionAlternative*>(
               &_SpeechRecognitionAlternative_default_instance_);
  }
  static PROTOBUF_CONSTEXPR int const kIndexInFileMessages =
    13;

  void Swap(SpeechRecognitionAlternative* other);
  friend void swap(SpeechRecognitionAlternative& a, SpeechRecognitionAlternative& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SpeechRecognitionAlternative* New() const PROTOBUF_FINAL { return New(NULL); }

  SpeechRecognitionAlternative* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
  void CopyFrom(const SpeechRecognitionAlternative& from);
  void MergeFrom(const SpeechRecognitionAlternative& from);
  void Clear() PROTOBUF_FINAL;
  bool IsInitialized() const PROTOBUF_FINAL;

  size_t ByteSizeLong() const PROTOBUF_FINAL;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const PROTOBUF_FINAL;
  void InternalSwap(SpeechRecognitionAlternative* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // string transcript = 1;
  void clear_transcript();
  static const int kTranscriptFieldNumber = 1;
  const ::std::string& transcript() const;
  void set_transcript(const ::std::string& value);
  #if LANG_CXX11
  void set_transcript(::std::string&& value);
  #endif
  void set_transcript(const char* value);
  void set_transcript(const char* value, size_t size);
  ::std::string* mutable_transcript();
  ::std::string* release_transcript();
  void set_allocated_transcript(::std::string* transcript);

  // float confidence = 2;
  void clear_confidence();
  static const int kConfidenceFieldNumber = 2;
  float confidence() const;
  void set_confidence(float value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr transcript_;
  float confidence_;
  mutable int _cached_size_;
  friend struct ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::TableStruct;
  friend void ::protobuf_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto::InitDefaultsSpeechRecognitionAlternativeImpl();
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// SyncRecognizeRequest

// .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
inline bool SyncRecognizeRequest::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
inline void SyncRecognizeRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) {
    delete config_;
  }
  config_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionConfig& SyncRecognizeRequest::config() const {
  const ::google::cloud::speech::v1beta1::RecognitionConfig* p = config_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  return p != NULL ? *p : *reinterpret_cast<const ::google::cloud::speech::v1beta1::RecognitionConfig*>(
      &::google::cloud::speech::v1beta1::_RecognitionConfig_default_instance_);
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* SyncRecognizeRequest::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* SyncRecognizeRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  return config_;
}
inline void SyncRecognizeRequest::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete config_;
  }
  if (config) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      config = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, config, submessage_arena);
    }
    
  } else {
    
  }
  config_ = config;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
}

// .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
inline bool SyncRecognizeRequest::has_audio() const {
  return this != internal_default_instance() && audio_ != NULL;
}
inline void SyncRecognizeRequest::clear_audio() {
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) {
    delete audio_;
  }
  audio_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionAudio& SyncRecognizeRequest::audio() const {
  const ::google::cloud::speech::v1beta1::RecognitionAudio* p = audio_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  return p != NULL ? *p : *reinterpret_cast<const ::google::cloud::speech::v1beta1::RecognitionAudio*>(
      &::google::cloud::speech::v1beta1::_RecognitionAudio_default_instance_);
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* SyncRecognizeRequest::release_audio() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  
  ::google::cloud::speech::v1beta1::RecognitionAudio* temp = audio_;
  audio_ = NULL;
  return temp;
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* SyncRecognizeRequest::mutable_audio() {
  
  if (audio_ == NULL) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  return audio_;
}
inline void SyncRecognizeRequest::set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete audio_;
  }
  if (audio) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      audio = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, audio, submessage_arena);
    }
    
  } else {
    
  }
  audio_ = audio;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
}

// -------------------------------------------------------------------

// AsyncRecognizeRequest

// .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
inline bool AsyncRecognizeRequest::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
inline void AsyncRecognizeRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) {
    delete config_;
  }
  config_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionConfig& AsyncRecognizeRequest::config() const {
  const ::google::cloud::speech::v1beta1::RecognitionConfig* p = config_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  return p != NULL ? *p : *reinterpret_cast<const ::google::cloud::speech::v1beta1::RecognitionConfig*>(
      &::google::cloud::speech::v1beta1::_RecognitionConfig_default_instance_);
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* AsyncRecognizeRequest::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* AsyncRecognizeRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  return config_;
}
inline void AsyncRecognizeRequest::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete config_;
  }
  if (config) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      config = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, config, submessage_arena);
    }
    
  } else {
    
  }
  config_ = config;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
}

// .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
inline bool AsyncRecognizeRequest::has_audio() const {
  return this != internal_default_instance() && audio_ != NULL;
}
inline void AsyncRecognizeRequest::clear_audio() {
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) {
    delete audio_;
  }
  audio_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionAudio& AsyncRecognizeRequest::audio() const {
  const ::google::cloud::speech::v1beta1::RecognitionAudio* p = audio_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  return p != NULL ? *p : *reinterpret_cast<const ::google::cloud::speech::v1beta1::RecognitionAudio*>(
      &::google::cloud::speech::v1beta1::_RecognitionAudio_default_instance_);
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* AsyncRecognizeRequest::release_audio() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  
  ::google::cloud::speech::v1beta1::RecognitionAudio* temp = audio_;
  audio_ = NULL;
  return temp;
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* AsyncRecognizeRequest::mutable_audio() {
  
  if (audio_ == NULL) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  return audio_;
}
inline void AsyncRecognizeRequest::set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete audio_;
  }
  if (audio) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      audio = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, audio, submessage_arena);
    }
    
  } else {
    
  }
  audio_ = audio;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
}

// -------------------------------------------------------------------

// StreamingRecognizeRequest

// .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
inline bool StreamingRecognizeRequest::has_streaming_config() const {
  return streaming_request_case() == kStreamingConfig;
}
inline void StreamingRecognizeRequest::set_has_streaming_config() {
  _oneof_case_[0] = kStreamingConfig;
}
inline void StreamingRecognizeRequest::clear_streaming_config() {
  if (has_streaming_config()) {
    delete streaming_request_.streaming_config_;
    clear_has_streaming_request();
  }
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* StreamingRecognizeRequest::release_streaming_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  if (has_streaming_config()) {
    clear_has_streaming_request();
      ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* temp = streaming_request_.streaming_config_;
    streaming_request_.streaming_config_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
inline const ::google::cloud::speech::v1beta1::StreamingRecognitionConfig& StreamingRecognizeRequest::streaming_config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  return has_streaming_config()
      ? *streaming_request_.streaming_config_
      : *reinterpret_cast< ::google::cloud::speech::v1beta1::StreamingRecognitionConfig*>(&::google::cloud::speech::v1beta1::_StreamingRecognitionConfig_default_instance_);
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* StreamingRecognizeRequest::mutable_streaming_config() {
  if (!has_streaming_config()) {
    clear_streaming_request();
    set_has_streaming_config();
    streaming_request_.streaming_config_ = new ::google::cloud::speech::v1beta1::StreamingRecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  return streaming_request_.streaming_config_;
}

// bytes audio_content = 2;
inline bool StreamingRecognizeRequest::has_audio_content() const {
  return streaming_request_case() == kAudioContent;
}
inline void StreamingRecognizeRequest::set_has_audio_content() {
  _oneof_case_[0] = kAudioContent;
}
inline void StreamingRecognizeRequest::clear_audio_content() {
  if (has_audio_content()) {
    streaming_request_.audio_content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_streaming_request();
  }
}
inline const ::std::string& StreamingRecognizeRequest::audio_content() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (has_audio_content()) {
    return streaming_request_.audio_content_.GetNoArena();
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
inline void StreamingRecognizeRequest::set_audio_content(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
#if LANG_CXX11
inline void StreamingRecognizeRequest::set_audio_content(::std::string&& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
#endif
inline void StreamingRecognizeRequest::set_audio_content(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
inline void StreamingRecognizeRequest::set_audio_content(const void* value, size_t size) {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
inline ::std::string* StreamingRecognizeRequest::mutable_audio_content() {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  return streaming_request_.audio_content_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* StreamingRecognizeRequest::release_audio_content() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (has_audio_content()) {
    clear_has_streaming_request();
    return streaming_request_.audio_content_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
inline void StreamingRecognizeRequest::set_allocated_audio_content(::std::string* audio_content) {
  if (!has_audio_content()) {
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_streaming_request();
  if (audio_content != NULL) {
    set_has_audio_content();
    streaming_request_.audio_content_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        audio_content);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}

inline bool StreamingRecognizeRequest::has_streaming_request() const {
  return streaming_request_case() != STREAMING_REQUEST_NOT_SET;
}
inline void StreamingRecognizeRequest::clear_has_streaming_request() {
  _oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}
inline StreamingRecognizeRequest::StreamingRequestCase StreamingRecognizeRequest::streaming_request_case() const {
  return StreamingRecognizeRequest::StreamingRequestCase(_oneof_case_[0]);
}
// -------------------------------------------------------------------

// StreamingRecognitionConfig

// .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
inline bool StreamingRecognitionConfig::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
inline void StreamingRecognitionConfig::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) {
    delete config_;
  }
  config_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionConfig& StreamingRecognitionConfig::config() const {
  const ::google::cloud::speech::v1beta1::RecognitionConfig* p = config_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  return p != NULL ? *p : *reinterpret_cast<const ::google::cloud::speech::v1beta1::RecognitionConfig*>(
      &::google::cloud::speech::v1beta1::_RecognitionConfig_default_instance_);
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* StreamingRecognitionConfig::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* StreamingRecognitionConfig::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  return config_;
}
inline void StreamingRecognitionConfig::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete config_;
  }
  if (config) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      config = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, config, submessage_arena);
    }
    
  } else {
    
  }
  config_ = config;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
}

// bool single_utterance = 2;
inline void StreamingRecognitionConfig::clear_single_utterance() {
  single_utterance_ = false;
}
inline bool StreamingRecognitionConfig::single_utterance() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance)
  return single_utterance_;
}
inline void StreamingRecognitionConfig::set_single_utterance(bool value) {
  
  single_utterance_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance)
}

// bool interim_results = 3;
inline void StreamingRecognitionConfig::clear_interim_results() {
  interim_results_ = false;
}
inline bool StreamingRecognitionConfig::interim_results() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results)
  return interim_results_;
}
inline void StreamingRecognitionConfig::set_interim_results(bool value) {
  
  interim_results_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results)
}

// -------------------------------------------------------------------

// RecognitionConfig

// .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
inline void RecognitionConfig::clear_encoding() {
  encoding_ = 0;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding RecognitionConfig::encoding() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.encoding)
  return static_cast< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding >(encoding_);
}
inline void RecognitionConfig::set_encoding(::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding value) {
  
  encoding_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.encoding)
}

// int32 sample_rate = 2;
inline void RecognitionConfig::clear_sample_rate() {
  sample_rate_ = 0;
}
inline ::google::protobuf::int32 RecognitionConfig::sample_rate() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.sample_rate)
  return sample_rate_;
}
inline void RecognitionConfig::set_sample_rate(::google::protobuf::int32 value) {
  
  sample_rate_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.sample_rate)
}

// string language_code = 3;
inline void RecognitionConfig::clear_language_code() {
  language_code_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& RecognitionConfig::language_code() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  return language_code_.GetNoArena();
}
inline void RecognitionConfig::set_language_code(const ::std::string& value) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
#if LANG_CXX11
inline void RecognitionConfig::set_language_code(::std::string&& value) {
  
  language_code_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
#endif
inline void RecognitionConfig::set_language_code(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
inline void RecognitionConfig::set_language_code(const char* value, size_t size) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
inline ::std::string* RecognitionConfig::mutable_language_code() {
  
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  return language_code_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecognitionConfig::release_language_code() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  
  return language_code_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RecognitionConfig::set_allocated_language_code(::std::string* language_code) {
  if (language_code != NULL) {
    
  } else {
    
  }
  language_code_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), language_code);
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}

// int32 max_alternatives = 4;
inline void RecognitionConfig::clear_max_alternatives() {
  max_alternatives_ = 0;
}
inline ::google::protobuf::int32 RecognitionConfig::max_alternatives() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives)
  return max_alternatives_;
}
inline void RecognitionConfig::set_max_alternatives(::google::protobuf::int32 value) {
  
  max_alternatives_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives)
}

// bool profanity_filter = 5;
inline void RecognitionConfig::clear_profanity_filter() {
  profanity_filter_ = false;
}
inline bool RecognitionConfig::profanity_filter() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter)
  return profanity_filter_;
}
inline void RecognitionConfig::set_profanity_filter(bool value) {
  
  profanity_filter_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter)
}

// .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
inline bool RecognitionConfig::has_speech_context() const {
  return this != internal_default_instance() && speech_context_ != NULL;
}
inline void RecognitionConfig::clear_speech_context() {
  if (GetArenaNoVirtual() == NULL && speech_context_ != NULL) {
    delete speech_context_;
  }
  speech_context_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::SpeechContext& RecognitionConfig::speech_context() const {
  const ::google::cloud::speech::v1beta1::SpeechContext* p = speech_context_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  return p != NULL ? *p : *reinterpret_cast<const ::google::cloud::speech::v1beta1::SpeechContext*>(
      &::google::cloud::speech::v1beta1::_SpeechContext_default_instance_);
}
inline ::google::cloud::speech::v1beta1::SpeechContext* RecognitionConfig::release_speech_context() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  
  ::google::cloud::speech::v1beta1::SpeechContext* temp = speech_context_;
  speech_context_ = NULL;
  return temp;
}
inline ::google::cloud::speech::v1beta1::SpeechContext* RecognitionConfig::mutable_speech_context() {
  
  if (speech_context_ == NULL) {
    speech_context_ = new ::google::cloud::speech::v1beta1::SpeechContext;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  return speech_context_;
}
inline void RecognitionConfig::set_allocated_speech_context(::google::cloud::speech::v1beta1::SpeechContext* speech_context) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete speech_context_;
  }
  if (speech_context) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      speech_context = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, speech_context, submessage_arena);
    }
    
  } else {
    
  }
  speech_context_ = speech_context;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
}

// -------------------------------------------------------------------

// SpeechContext

// repeated string phrases = 1;
inline int SpeechContext::phrases_size() const {
  return phrases_.size();
}
inline void SpeechContext::clear_phrases() {
  phrases_.Clear();
}
inline const ::std::string& SpeechContext::phrases(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Get(index);
}
inline ::std::string* SpeechContext::mutable_phrases(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Mutable(index);
}
inline void SpeechContext::set_phrases(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechContext.phrases)
  phrases_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void SpeechContext::set_phrases(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechContext.phrases)
  phrases_.Mutable(index)->assign(std::move(value));
}
#endif
inline void SpeechContext::set_phrases(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  phrases_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline void SpeechContext::set_phrases(int index, const char* value, size_t size) {
  phrases_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline ::std::string* SpeechContext::add_phrases() {
  // @@protoc_insertion_point(field_add_mutable:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Add();
}
inline void SpeechContext::add_phrases(const ::std::string& value) {
  phrases_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
#if LANG_CXX11
inline void SpeechContext::add_phrases(::std::string&& value) {
  phrases_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
#endif
inline void SpeechContext::add_phrases(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  phrases_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline void SpeechContext::add_phrases(const char* value, size_t size) {
  phrases_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
SpeechContext::phrases() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
SpeechContext::mutable_phrases() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return &phrases_;
}

// -------------------------------------------------------------------

// RecognitionAudio

// bytes content = 1;
inline bool RecognitionAudio::has_content() const {
  return audio_source_case() == kContent;
}
inline void RecognitionAudio::set_has_content() {
  _oneof_case_[0] = kContent;
}
inline void RecognitionAudio::clear_content() {
  if (has_content()) {
    audio_source_.content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_audio_source();
  }
}
inline const ::std::string& RecognitionAudio::content() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (has_content()) {
    return audio_source_.content_.GetNoArena();
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
inline void RecognitionAudio::set_content(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
#if LANG_CXX11
inline void RecognitionAudio::set_content(::std::string&& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
#endif
inline void RecognitionAudio::set_content(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
inline void RecognitionAudio::set_content(const void* value, size_t size) {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
inline ::std::string* RecognitionAudio::mutable_content() {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionAudio.content)
  return audio_source_.content_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecognitionAudio::release_content() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (has_content()) {
    clear_has_audio_source();
    return audio_source_.content_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
inline void RecognitionAudio::set_allocated_content(::std::string* content) {
  if (!has_content()) {
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_audio_source();
  if (content != NULL) {
    set_has_content();
    audio_source_.content_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        content);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionAudio.content)
}

// string uri = 2;
inline bool RecognitionAudio::has_uri() const {
  return audio_source_case() == kUri;
}
inline void RecognitionAudio::set_has_uri() {
  _oneof_case_[0] = kUri;
}
inline void RecognitionAudio::clear_uri() {
  if (has_uri()) {
    audio_source_.uri_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_audio_source();
  }
}
inline const ::std::string& RecognitionAudio::uri() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (has_uri()) {
    return audio_source_.uri_.GetNoArena();
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
inline void RecognitionAudio::set_uri(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
#if LANG_CXX11
inline void RecognitionAudio::set_uri(::std::string&& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
#endif
inline void RecognitionAudio::set_uri(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
inline void RecognitionAudio::set_uri(const char* value, size_t size) {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
inline ::std::string* RecognitionAudio::mutable_uri() {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  return audio_source_.uri_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecognitionAudio::release_uri() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (has_uri()) {
    clear_has_audio_source();
    return audio_source_.uri_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
inline void RecognitionAudio::set_allocated_uri(::std::string* uri) {
  if (!has_uri()) {
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_audio_source();
  if (uri != NULL) {
    set_has_uri();
    audio_source_.uri_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        uri);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}

inline bool RecognitionAudio::has_audio_source() const {
  return audio_source_case() != AUDIO_SOURCE_NOT_SET;
}
inline void RecognitionAudio::clear_has_audio_source() {
  _oneof_case_[0] = AUDIO_SOURCE_NOT_SET;
}
inline RecognitionAudio::AudioSourceCase RecognitionAudio::audio_source_case() const {
  return RecognitionAudio::AudioSourceCase(_oneof_case_[0]);
}
// -------------------------------------------------------------------

// SyncRecognizeResponse

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
inline int SyncRecognizeResponse::results_size() const {
  return results_.size();
}
inline void SyncRecognizeResponse::clear_results() {
  results_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& SyncRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* SyncRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* SyncRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
SyncRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return &results_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
SyncRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_;
}

// -------------------------------------------------------------------

// AsyncRecognizeResponse

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
inline int AsyncRecognizeResponse::results_size() const {
  return results_.size();
}
inline void AsyncRecognizeResponse::clear_results() {
  results_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& AsyncRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* AsyncRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* AsyncRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
AsyncRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return &results_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
AsyncRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_;
}

// -------------------------------------------------------------------

// AsyncRecognizeMetadata

// int32 progress_percent = 1;
inline void AsyncRecognizeMetadata::clear_progress_percent() {
  progress_percent_ = 0;
}
inline ::google::protobuf::int32 AsyncRecognizeMetadata::progress_percent() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent)
  return progress_percent_;
}
inline void AsyncRecognizeMetadata::set_progress_percent(::google::protobuf::int32 value) {
  
  progress_percent_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent)
}

// .google.protobuf.Timestamp start_time = 2;
inline bool AsyncRecognizeMetadata::has_start_time() const {
  return this != internal_default_instance() && start_time_ != NULL;
}
inline const ::google::protobuf::Timestamp& AsyncRecognizeMetadata::start_time() const {
  const ::google::protobuf::Timestamp* p = start_time_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Timestamp*>(
      &::google::protobuf::_Timestamp_default_instance_);
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::release_start_time() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  
  ::google::protobuf::Timestamp* temp = start_time_;
  start_time_ = NULL;
  return temp;
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::mutable_start_time() {
  
  if (start_time_ == NULL) {
    start_time_ = new ::google::protobuf::Timestamp;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  return start_time_;
}
inline void AsyncRecognizeMetadata::set_allocated_start_time(::google::protobuf::Timestamp* start_time) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(start_time_);
  }
  if (start_time) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast< ::google::protobuf::MessageLite*>(start_time)->GetArena();
    if (message_arena != submessage_arena) {
      start_time = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, start_time, submessage_arena);
    }
    
  } else {
    
  }
  start_time_ = start_time;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
}

// .google.protobuf.Timestamp last_update_time = 3;
inline bool AsyncRecognizeMetadata::has_last_update_time() const {
  return this != internal_default_instance() && last_update_time_ != NULL;
}
inline const ::google::protobuf::Timestamp& AsyncRecognizeMetadata::last_update_time() const {
  const ::google::protobuf::Timestamp* p = last_update_time_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Timestamp*>(
      &::google::protobuf::_Timestamp_default_instance_);
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::release_last_update_time() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  
  ::google::protobuf::Timestamp* temp = last_update_time_;
  last_update_time_ = NULL;
  return temp;
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::mutable_last_update_time() {
  
  if (last_update_time_ == NULL) {
    last_update_time_ = new ::google::protobuf::Timestamp;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  return last_update_time_;
}
inline void AsyncRecognizeMetadata::set_allocated_last_update_time(::google::protobuf::Timestamp* last_update_time) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(last_update_time_);
  }
  if (last_update_time) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast< ::google::protobuf::MessageLite*>(last_update_time)->GetArena();
    if (message_arena != submessage_arena) {
      last_update_time = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, last_update_time, submessage_arena);
    }
    
  } else {
    
  }
  last_update_time_ = last_update_time;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
}

// -------------------------------------------------------------------

// StreamingRecognizeResponse

// .google.rpc.Status error = 1;
inline bool StreamingRecognizeResponse::has_error() const {
  return this != internal_default_instance() && error_ != NULL;
}
inline const ::google::rpc::Status& StreamingRecognizeResponse::error() const {
  const ::google::rpc::Status* p = error_;
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  return p != NULL ? *p : *reinterpret_cast<const ::google::rpc::Status*>(
      &::google::rpc::_Status_default_instance_);
}
inline ::google::rpc::Status* StreamingRecognizeResponse::release_error() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  
  ::google::rpc::Status* temp = error_;
  error_ = NULL;
  return temp;
}
inline ::google::rpc::Status* StreamingRecognizeResponse::mutable_error() {
  
  if (error_ == NULL) {
    error_ = new ::google::rpc::Status;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  return error_;
}
inline void StreamingRecognizeResponse::set_allocated_error(::google::rpc::Status* error) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(error_);
  }
  if (error) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      error = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, error, submessage_arena);
    }
    
  } else {
    
  }
  error_ = error;
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
}

// repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
inline int StreamingRecognizeResponse::results_size() const {
  return results_.size();
}
inline void StreamingRecognizeResponse::clear_results() {
  results_.Clear();
}
inline const ::google::cloud::speech::v1beta1::StreamingRecognitionResult& StreamingRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Get(index);
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionResult* StreamingRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionResult* StreamingRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >*
StreamingRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return &results_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >&
StreamingRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_;
}

// int32 result_index = 3;
inline void StreamingRecognizeResponse::clear_result_index() {
  result_index_ = 0;
}
inline ::google::protobuf::int32 StreamingRecognizeResponse::result_index() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index)
  return result_index_;
}
inline void StreamingRecognizeResponse::set_result_index(::google::protobuf::int32 value) {
  
  result_index_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index)
}

// .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
inline void StreamingRecognizeResponse::clear_endpointer_type() {
  endpointer_type_ = 0;
}
inline ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::endpointer_type() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type)
  return static_cast< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType >(endpointer_type_);
}
inline void StreamingRecognizeResponse::set_endpointer_type(::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType value) {
  
  endpointer_type_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type)
}

// -------------------------------------------------------------------

// StreamingRecognitionResult

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
inline int StreamingRecognitionResult::alternatives_size() const {
  return alternatives_.size();
}
inline void StreamingRecognitionResult::clear_alternatives() {
  alternatives_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& StreamingRecognitionResult::alternatives(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* StreamingRecognitionResult::mutable_alternatives(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* StreamingRecognitionResult::add_alternatives() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
StreamingRecognitionResult::mutable_alternatives() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return &alternatives_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
StreamingRecognitionResult::alternatives() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_;
}

// bool is_final = 2;
inline void StreamingRecognitionResult::clear_is_final() {
  is_final_ = false;
}
inline bool StreamingRecognitionResult::is_final() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final)
  return is_final_;
}
inline void StreamingRecognitionResult::set_is_final(bool value) {
  
  is_final_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final)
}

// float stability = 3;
inline void StreamingRecognitionResult::clear_stability() {
  stability_ = 0;
}
inline float StreamingRecognitionResult::stability() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.stability)
  return stability_;
}
inline void StreamingRecognitionResult::set_stability(float value) {
  
  stability_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionResult.stability)
}

// -------------------------------------------------------------------

// SpeechRecognitionResult

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
inline int SpeechRecognitionResult::alternatives_size() const {
  return alternatives_.size();
}
inline void SpeechRecognitionResult::clear_alternatives() {
  alternatives_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& SpeechRecognitionResult::alternatives(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* SpeechRecognitionResult::mutable_alternatives(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* SpeechRecognitionResult::add_alternatives() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
SpeechRecognitionResult::mutable_alternatives() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return &alternatives_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
SpeechRecognitionResult::alternatives() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_;
}

// -------------------------------------------------------------------

// SpeechRecognitionAlternative

// string transcript = 1;
inline void SpeechRecognitionAlternative::clear_transcript() {
  transcript_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SpeechRecognitionAlternative::transcript() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  return transcript_.GetNoArena();
}
inline void SpeechRecognitionAlternative::set_transcript(const ::std::string& value) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
#if LANG_CXX11
inline void SpeechRecognitionAlternative::set_transcript(::std::string&& value) {
  
  transcript_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
#endif
inline void SpeechRecognitionAlternative::set_transcript(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
inline void SpeechRecognitionAlternative::set_transcript(const char* value, size_t size) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
inline ::std::string* SpeechRecognitionAlternative::mutable_transcript() {
  
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  return transcript_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SpeechRecognitionAlternative::release_transcript() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  
  return transcript_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SpeechRecognitionAlternative::set_allocated_transcript(::std::string* transcript) {
  if (transcript != NULL) {
    
  } else {
    
  }
  transcript_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), transcript);
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}

// float confidence = 2;
inline void SpeechRecognitionAlternative::clear_confidence() {
  confidence_ = 0;
}
inline float SpeechRecognitionAlternative::confidence() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence)
  return confidence_;
}
inline void SpeechRecognitionAlternative::set_confidence(float value) {
  
  confidence_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace v1beta1
}  // namespace speech
}  // namespace cloud
}  // namespace google

namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding>() {
  return ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding_descriptor();
}
template <> struct is_proto_enum< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType>() {
  return ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType_descriptor();
}

}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto__INCLUDED
